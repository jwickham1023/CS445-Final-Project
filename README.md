# CS445 Final Project: Curriculum Learning for Robust Number Classification

In the real world, perfect data is never guaranteed. Images could be blurry, noisy, off-center, or distorted in ways that models are unprepared for. We wanted to explore how a lightweight model handles the messy reality of the real world. To accomplish this, we started with the MNIST dataset as a controlled baseline for digit recognition. From that baseline, we introduced MNIST-C—a corrupted version of MNIST—plus a bonus set that introduced a combined total of thirty synthetic distortions. The model was never exposed to any of these during initial training, which gave us a clean benchmark for assessing generalization. From there, we implemented a curriculum-based training pipeline, where the model gradually learned to handle increasing levels of corruption. This provided a structured way of improving generalization without overfitting any single corruption type. To test its ability to generalize across domains, we finally evaluated the trained model on EMNIST, a dataset with digits written in different handwriting styles. This project is ultimately about building models that can handle imperfection, perform well under ideal conditions, and still hold up when the data gets messy.
